{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.2.0.json: 128kB [00:02, 44.4kB/s]\n",
      "2021-05-05 23:02:23 INFO: Downloading default packages for language: ru (Russian)...\n",
      "Downloading http://nlp.stanford.edu/software/stanza/1.2.0/ru/default.zip: 100%|█████| 574M/574M [04:28<00:00, 2.13MB/s]\n",
      "2021-05-05 23:07:28 INFO: Finished downloading models and saved to C:\\Users\\M\\stanza_resources.\n"
     ]
    }
   ],
   "source": [
    "#stanza.download('ru')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-14 00:44:29 INFO: Loading these models for language: ru (Russian):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | syntagrus |\n",
      "| pos       | syntagrus |\n",
      "| lemma     | syntagrus |\n",
      "| depparse  | syntagrus |\n",
      "=========================\n",
      "\n",
      "2021-05-14 00:44:29 INFO: Use device: cpu\n",
      "2021-05-14 00:44:29 INFO: Loading: tokenize\n",
      "2021-05-14 00:44:29 INFO: Loading: pos\n",
      "2021-05-14 00:44:31 INFO: Loading: lemma\n",
      "2021-05-14 00:44:32 INFO: Loading: depparse\n",
      "2021-05-14 00:44:36 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 1\tword: Волга\thead id: 2\thead: впадает\tdeprel: nsubj\n",
      "id: 2\tword: впадает\thead id: 0\thead: root\tdeprel: root\n",
      "id: 3\tword: в\thead id: 5\thead: море\tdeprel: case\n",
      "id: 4\tword: Каспийское\thead id: 5\thead: море\tdeprel: amod\n",
      "id: 5\tword: море\thead id: 2\thead: впадает\tdeprel: obl\n"
     ]
    }
   ],
   "source": [
    "nlp = stanza.Pipeline(lang='ru', processors='tokenize,pos,lemma,depparse')\n",
    "doc = nlp('Волга впадает в Каспийское море')\n",
    "print(*[f'id: {word.id}\\tword: {word.text}\\thead id: {word.head}\\thead: {sent.words[word.head-1].text if word.head > 0 else \"root\"}\\tdeprel: {word.deprel}' for sent in doc.sentences for word in sent.words], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 1\tword: Он\thead id: 2\thead: убил\tdeprel: nsubj\n",
      "id: 2\tword: убил\thead id: 0\thead: root\tdeprel: root\n",
      "id: 3\tword: служанку\thead id: 2\thead: убил\tdeprel: obj\n",
      "id: 4\tword: актрисы\thead id: 3\thead: служанку\tdeprel: nmod\n",
      "id: 5\tword: ,\thead id: 7\thead: стояла\tdeprel: punct\n",
      "id: 6\tword: Она\thead id: 7\thead: стояла\tdeprel: nsubj\n",
      "id: 7\tword: стояла\thead id: 2\thead: убил\tdeprel: conj\n",
      "id: 8\tword: на\thead id: 9\thead: балконе\tdeprel: case\n",
      "id: 9\tword: балконе\thead id: 7\thead: стояла\tdeprel: obl\n"
     ]
    }
   ],
   "source": [
    "doc1 = nlp('Он убил служанку актрисы, Она стояла на балконе')\n",
    "print(*[f'id: {word.id}\\tword: {word.text}\\thead id: {word.head}\\thead: {sent.words[word.head-1].text if word.head > 0 else \"root\"}\\tdeprel: {word.deprel}' for sent in doc1.sentences for word in sent.words], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = 'и в не что он на с я как она то его а но это к так же ее за было вы у по да все о бы только от из ему ты мне сказал меня всё еще был стр когда нет теперь строка вот него ни для ли вместо уже быть или они себя была до ей ну если их вас ж даже очень вдруг ней мы ничего опять вам того сказала есть себе были г во этого нибудь чем может после чтобы потом изд уж потому время где тем со ним говорил ведь тут будет без надо будто '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_tags = nlp(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "pos = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": 39,\n",
      "  \"text\": \"был\",\n",
      "  \"lemma\": \"быть\",\n",
      "  \"upos\": \"AUX\",\n",
      "  \"feats\": \"Aspect=Imp|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act\",\n",
      "  \"head\": 35,\n",
      "  \"deprel\": \"aux\",\n",
      "  \"misc\": \"start_char=129|end_char=132\"\n",
      "}\n",
      "{\n",
      "  \"id\": 40,\n",
      "  \"text\": \"стр\",\n",
      "  \"lemma\": \"стр\",\n",
      "  \"upos\": \"NOUN\",\n",
      "  \"feats\": \"Animacy=Inan|Case=Nom|Gender=Masc|Number=Sing\",\n",
      "  \"head\": 35,\n",
      "  \"deprel\": \"nsubj\",\n",
      "  \"misc\": \"start_char=133|end_char=136\"\n",
      "}\n",
      "{\n",
      "  \"id\": 44,\n",
      "  \"text\": \"строка\",\n",
      "  \"lemma\": \"строка\",\n",
      "  \"upos\": \"NOUN\",\n",
      "  \"feats\": \"Animacy=Inan|Case=Nom|Gender=Fem|Number=Sing\",\n",
      "  \"head\": 42,\n",
      "  \"deprel\": \"nsubj\",\n",
      "  \"misc\": \"start_char=154|end_char=160\"\n",
      "}\n",
      "{\n",
      "  \"id\": 56,\n",
      "  \"text\": \"была\",\n",
      "  \"lemma\": \"быть\",\n",
      "  \"upos\": \"AUX\",\n",
      "  \"feats\": \"Aspect=Imp|Gender=Fem|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act\",\n",
      "  \"head\": 42,\n",
      "  \"deprel\": \"conj\",\n",
      "  \"misc\": \"start_char=209|end_char=213\"\n",
      "}\n",
      "{\n",
      "  \"id\": 76,\n",
      "  \"text\": \"были\",\n",
      "  \"lemma\": \"быть\",\n",
      "  \"upos\": \"AUX\",\n",
      "  \"feats\": \"Aspect=Imp|Mood=Ind|Number=Plur|Tense=Past|VerbForm=Fin|Voice=Act\",\n",
      "  \"head\": 73,\n",
      "  \"deprel\": \"aux\",\n",
      "  \"misc\": \"start_char=301|end_char=305\"\n",
      "}\n",
      "{\n",
      "  \"id\": 77,\n",
      "  \"text\": \"г\",\n",
      "  \"lemma\": \"год\",\n",
      "  \"upos\": \"NOUN\",\n",
      "  \"feats\": \"Animacy=Inan|Case=Nom|Gender=Masc|Number=Plur\",\n",
      "  \"head\": 73,\n",
      "  \"deprel\": \"obl\",\n",
      "  \"misc\": \"start_char=306|end_char=307\"\n",
      "}\n",
      "{\n",
      "  \"id\": 80,\n",
      "  \"text\": \"нибудь\",\n",
      "  \"lemma\": \"нибудь\",\n",
      "  \"upos\": \"PUNCT\",\n",
      "  \"head\": 82,\n",
      "  \"deprel\": \"punct\",\n",
      "  \"misc\": \"start_char=317|end_char=323\"\n",
      "}\n",
      "{\n",
      "  \"id\": 86,\n",
      "  \"text\": \"изд\",\n",
      "  \"lemma\": \"изд\",\n",
      "  \"upos\": \"NOUN\",\n",
      "  \"feats\": \"Animacy=Inan|Case=Nom|Gender=Neut|Number=Sing\",\n",
      "  \"head\": 94,\n",
      "  \"deprel\": \"nsubj\",\n",
      "  \"misc\": \"start_char=352|end_char=355\"\n",
      "}\n",
      "{\n",
      "  \"id\": 89,\n",
      "  \"text\": \"время\",\n",
      "  \"lemma\": \"время\",\n",
      "  \"upos\": \"NOUN\",\n",
      "  \"feats\": \"Animacy=Inan|Case=Nom|Gender=Neut|Number=Sing\",\n",
      "  \"head\": 94,\n",
      "  \"deprel\": \"nsubj\",\n",
      "  \"misc\": \"start_char=366|end_char=371\"\n",
      "}\n",
      "{\n",
      "  \"id\": 97,\n",
      "  \"text\": \"будет\",\n",
      "  \"lemma\": \"быть\",\n",
      "  \"upos\": \"AUX\",\n",
      "  \"feats\": \"Aspect=Imp|Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin|Voice=Act\",\n",
      "  \"head\": 99,\n",
      "  \"deprel\": \"cop\",\n",
      "  \"misc\": \"start_char=404|end_char=409\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({'CCONJ': 10,\n",
       "         'ADP': 34,\n",
       "         'PART': 28,\n",
       "         'PRON': 60,\n",
       "         'SCONJ': 8,\n",
       "         'ADV': 24,\n",
       "         'VERB': 16,\n",
       "         'AUX': 8,\n",
       "         'NOUN': 10,\n",
       "         'PUNCT': 2})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for sent in words_tags.sentences:\n",
    "    for word in sent.words:\n",
    "        pos.append(word.upos)\n",
    "        if word.upos in ('PUNCT','AUX', 'NOUN'):\n",
    "            print(word)\n",
    "Counter(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-6300192a652f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdoc1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'|'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "doc1.sentences[0].words[4].feats.split('|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"id\": 1,\n",
       "  \"text\": \"Он\",\n",
       "  \"lemma\": \"он\",\n",
       "  \"upos\": \"PRON\",\n",
       "  \"feats\": \"Case=Nom|Gender=Masc|Number=Sing|Person=3\",\n",
       "  \"head\": 2,\n",
       "  \"deprel\": \"nsubj\",\n",
       "  \"misc\": \"start_char=0|end_char=2\"\n",
       "}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1.sentences[0].words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-f2fb6bf8df70>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;34m''\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'='\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdoc1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'|'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "''.join((i.split('=')[-1] for i in doc1.sentences[0].words[4].feats.split('|')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_files(file, path_to_result):\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        main_text = f.read()\n",
    "    result = parce(main_text)\n",
    "    with open(path_to_result + '/' + file, 'w', encoding='utf-8') as f:\n",
    "        f.write(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "def parce(text):\n",
    "    result_list = []\n",
    "    print(0)\n",
    "    all_tags_text = nlp(text)\n",
    "    print(1)\n",
    "    for sent in tqdm(all_tags_text.sentences):\n",
    "        for word in sent.words:\n",
    "            result_list.append(word.lemma)\n",
    "    result = ' '.join(result_list)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path_to_result = 'D:/Nika/3/lingstylo/stanza_new_lemms/corpus'\n",
    "path_to_tags = 'D:/Nika/3/lingstylo/stanza_new_parsed_texts/corpus'\n",
    "os.makedirs(path_to_result)\n",
    "os.makedirs(path_to_tags)\n",
    "for path, dirs, files in os.walk('D:/Nika/3/lingstylo/corpus_new/corpus'):\n",
    "    for file in files:\n",
    "        test(path, file, path_to_tags, path_to_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(path, file, path_to_tags, path_to_result):\n",
    "    with open(path + '/' + file, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "\n",
    "    result_list = []\n",
    "    print(0)\n",
    "    all_tags_text = nlp(text)\n",
    "    print(1)        \n",
    "\n",
    "    with open(path_to_tags + '/' + file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(all_tags_text.to_dict(), f)\n",
    "\n",
    "    for sent in all_tags_text.sentences:\n",
    "        for word in sent.words:\n",
    "            result_list.append(word.lemma)\n",
    "    result = ' '.join(result_list)\n",
    "\n",
    "    with open(path_to_result + '/' + file, 'w', encoding='utf-8') as f:\n",
    "        f.write(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
